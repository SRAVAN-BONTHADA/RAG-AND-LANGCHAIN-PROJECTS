{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Simulating the input sentence\n",
        "input_sentence = \"Explain about data science in few\"\n",
        "\n",
        "# Simulating vocabulary and vector representations (for simplicity, we'll use random vectors here)\n",
        "vocabulary = [\"words\", \"details\", \"examples\", \"minutes\", \"things\"]\n",
        "word_vectors = {word: np.random.rand(10) for word in vocabulary}  # Each word is represented by a random 10-dimensional vector\n",
        "\n",
        "# Simulating the context vector (for simplicity, using a random vector here as well)\n",
        "context_vector = np.random.rand(10)\n",
        "\n",
        "# Compute similarity (dot product) between context vector and each word's vector (simulating self-attention)\n",
        "similarity_scores = {word: np.dot(context_vector, word_vectors[word]) for word in vocabulary}\n",
        "\n",
        "# Convert similarity scores to probabilities using softmax\n",
        "def softmax(scores):\n",
        "    exp_scores = np.exp(list(scores.values()))\n",
        "    return {word: exp_score / sum(exp_scores) for word, exp_score in zip(scores.keys(), exp_scores)}\n",
        "\n",
        "probabilities = softmax(similarity_scores)\n",
        "\n",
        "# Output the word with the highest probability (prediction)\n",
        "predicted_word = max(probabilities, key=probabilities.get)\n",
        "\n",
        "print(f\"Predicted next word: {predicted_word}\")\n",
        "print(f\"Probability distribution: {probabilities}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75V6w5b8hKtO",
        "outputId": "e03eef58-6830-4180-ebbf-3d5f6420bd1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next word: words\n",
            "Probability distribution: {'words': 0.3184663650725377, 'details': 0.22229013267754427, 'examples': 0.25580033331526314, 'minutes': 0.06415318556667615, 'things': 0.13928998336797874}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "assMleW4hKxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import faiss\n",
        "import numpy as np\n",
        "from huggingface_hub import InferenceClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Hugging Face API key and client setup\n",
        "API_KEY = \"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\"\n",
        "client = InferenceClient(api_key=API_KEY)\n",
        "\n",
        "# Initialize embedding model for document retrieval\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Example documents\n",
        "documents = [\n",
        "    \"The capital of France is Paris.\",\n",
        "    \"The largest planet in our solar system is Jupiter.\",\n",
        "    \"Python is a programming language used for web development, data science, and more.\",\n",
        "    \"The Great Wall of China is one of the Seven Wonders of the World.\",\n",
        "]\n",
        "\n",
        "# Step 1: Index documents with FAISS\n",
        "def index_documents(documents):\n",
        "    embeddings = embedding_model.encode(documents, convert_to_tensor=False)\n",
        "    dimension = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(embeddings)\n",
        "    return index, embeddings\n",
        "\n",
        "index, document_embeddings = index_documents(documents)\n",
        "\n",
        "def retrieve_relevant_docs(query, k=2):\n",
        "    \"\"\"\n",
        "    Retrieve the top-k relevant documents using FAISS.\n",
        "    \"\"\"\n",
        "    query_embedding = embedding_model.encode([query], convert_to_tensor=False)\n",
        "    distances, indices = index.search(np.array(query_embedding, dtype=np.float32), k)\n",
        "    return [documents[i] for i in indices[0]]\n",
        "\n",
        "def generate_answer(query):\n",
        "    \"\"\"\n",
        "    Retrieve relevant documents and generate an answer using the Phi model via Hugging Face API.\n",
        "    \"\"\"\n",
        "    # Retrieve relevant documents\n",
        "    relevant_docs = retrieve_relevant_docs(query)\n",
        "    context = \"\\n\".join(relevant_docs)\n",
        "\n",
        "    # Create a prompt for the Phi model\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuery: {query}\\n\\nAnswer:\"}\n",
        "    ]\n",
        "\n",
        "    # Call the Hugging Face API with the Phi model\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"microsoft/Phi-3.5-mini-instruct\",\n",
        "        messages=messages,\n",
        "        max_tokens=500\n",
        "    )\n",
        "\n",
        "    # Extract and return the generated response\n",
        "    return completion.choices[0].message[\"content\"]\n",
        "\n",
        "# Example usage\n",
        "query = \"What is the largest planet in the solar system?\"\n",
        "answer = generate_answer(query)\n",
        "print(f\"Query: {query}\\nAnswer: {answer}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L1ti7KEChsn",
        "outputId": "f6c64c39-44ff-46a5-a6a2-9f87ea3d40d5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What is the largest planet in the solar system?\n",
            "Answer: The largest planet in the solar system is Jupiter. It is known for its massive size, massive storms including the famed Great Red Spot, and its prominent series of rings, though not as prominent as those of Saturn. Jupiter is a gas giant, primarily composed of hydrogen and helium, and its immense gravity has a significant influence on other objects within the solar system, including its moons and the asteroid belt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Querying with RAG\n",
        "def generate_query_response(query):\n",
        "    # Generate query embedding\n",
        "    query_embedding = embedding_model.encode([query], convert_to_tensor=False)[0]\n",
        "\n",
        "    # Search in Qdrant\n",
        "    search_results = qdrant_client.search(\n",
        "        collection_name=collection_name,\n",
        "        query_vector=query_embedding,\n",
        "        limit=1  # Fetch top 3 relevant documents\n",
        "    )\n",
        "\n",
        "    # Retrieve top documents\n",
        "    context = \"\\n\".join([result.payload[\"text\"] for result in search_results])\n",
        "\n",
        "    # Use Hugging Face API for RAG with context\n",
        "    prompt = f\"Answer the question based on the context below:\\n\\nContext: {context}\\n\\nQuestion: {query}\"\n",
        "    response = requests.post(\n",
        "        HF_MODEL_URL,\n",
        "        headers={\"Authorization\": f\"Bearer {HF_API_KEY}\"},\n",
        "        json={\"inputs\": prompt}\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}, {response.text}\")\n",
        "        return \"Failed to generate response.\"\n",
        "\n",
        "# Example query\n",
        "query = \"What is the largest planet?\"\n",
        "response = generate_query_response(query)\n",
        "print(\"Generated Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2wGgujRo60h",
        "outputId": "363e7e3d-abac-4d7f-cfb1-5341b622e0d9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Response: [{'generated_text': 'Answer the question based on the context below:\\n\\nContext: Jupiter is the largest planet in the solar system.\\n\\nQuestion: What is the largest planet?\\n\\nAnswer: Jupiter\\n\\n\\nContext: The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower.\\n\\nQuestion: Who is the architect behind the Eiffel Tower\\'s distinctive lattice design?\\n\\nAnswer: Gustave Eiffel\\n\\n\\nContext: Photosynthesis is a process used by plants and other organisms to convert light energy into chemical energy that can be later released to fuel the organisms\\' activities.\\n\\nQuestion: How do plants convert light energy into chemical energy during photosynthesis?\\n\\nAnswer: Through a process involving the absorption of light and its conversion into chemical energy in the presence of chlorophyll.\\n\\n\\nContext: In traditional Chinese culture, the phoenix (Fenghuang) symbolizes high virtue, grace, and elegance. Unlike other Chinese mythological birds, the phoenix represents feminine characteristics but can also embody the strength of both genders together.\\n\\nQuestion: What are the symbolic traits associated with the phoenix in Chinese mythology?\\n\\nAnswer: High virtue, grace, elegance, and both feminine and masculine strength.\\n\\n\\nContext: During a solar eclipse, the Moon passes between the Earth and the Sun, temporarily blocking all or part of the Sun\\'s image. This astronomical event can only occur during a new moon phase, when the Sun and the Moon are in conjunction as seen from the Earth. Solar eclipses can be total, annular, or partial, depending on the apparent sizes of the Sun and Moon, and the distance between them at that time.\\n\\nQuestion: Explain why solar eclipses happen during a new moon phase and not any other moon phase, and under what specific circumstances they can manifest as total, annular, or partial eclipses.\\n\\nAnswer: Solar eclipses occur during a new moon phase because that\\'s when the Moon orbits directly between the Earth and the Sun, casting a shadow on Earth\\'s surface. This alignment can only happen during the conjunction. The specific circumstances leading to a total, annular, or partial eclipse depend on the apparent sizes of the Sun and Moon and their distances from the Earth. A total eclipse occurs when the apparent size of the Moon is great enough to cover the Sun completely, an annular eclipse happens when the Moon\\'s apparent size is too small to cover the Sun, leaving a bright ring, and a partial eclipse takes place when only a portion of the Sun is obscured by the Moon.\\n\\n\\nContext: Plate tectonics is the scientific theory that describes the large-scale motion of seven large plates and the movements of a larger number of smaller plates of Earth\\'s lithosphere. This theory explains many features of our planet\\'s surface, including earthquakes, mountain ranges, and the formation of the oceanic and continental crust.\\n\\nQuestion: Can you analyze how plate tectonics might influence the formation of mountain ranges, earthquakes, and the distribution of oceanic and continental crust, detailing the underlying mechanisms and providing examples for each phenomenon?\\n\\nAnswer: Plate tectonics contributes significantly to the formation of mountain ranges. Whenever two continental plates converge, they can be forced upwards, forming large mountain ranges, as seen in the Himalayas where the Indian Plate and the Eurasian Plate collide. Similarly, oceanic plate subduction, where an oceanic plate slides under a continental plate due to its higher density, can result in volcanic mountain formation, such as the Andes in South America.\\n\\nEarthquakes are a direct result of the stresses and strain built up along plate boundaries from their perpetual interaction. When the stress overcomes the friction holding the plates in place, it results in an earthquake. The Ring of Fire, with its high seismic activity, is due to multiple plate boundaries there, notably convergent, divergent, and transform faults.\\n\\nThe distribution of oceanic and continental crust is influenced by the process of seafloor spreading at divergent boundaries. Magma rises from beneath the mid-ocean ridges to form new oceanic crust. As this new crust moves away from the ridges, oceanic crust leads to the formation of distinctive patterns such as the symmetric age-spreading observed in the mid-Atlantic ridge system. In contrast, older and denser oceanic crust tends to subduct beneath the less dense continental crust at convergent boundaries, which leads to the recycling of crust material into the mantle.\\n\\n\\nContext: The Las Vegas Strip is a renowned hub for gambling, entertainment, and dining. It has witnessed the evolution of casino architecture over the decades, transitioning from traditional design to innovative attractions such as permanent slot machines, live shows, and special events. Its hotels like the Venetian, Wynn, and Encore are notable examples of mixed-use development integrating opulent amenities.\\n\\nQuestion: Describe the developmental trajectory of the Las Vegas Strip\\'s architecture, attesting to its shift from classic designs to avant-garde features. Illustrate how this has impacted not only the casino industry but also the surrounding urban landscape. Ensure that in your analysis, references to specific edifices like the Venetian and temporal milestones such as the introduction of slot machines on permanently installed tracks are integrated, alongside the resulting socio-economic effects.\\n\\nAnswer: The architectural evolution of the Las Vegas Strip has been both transformative and reflective of broader cultural and technological advances. Initially, the Strip mirrored the traditional mindset of the gambling and casino industry with its sprawling hotel-casinos such as the Flamingo, which opened in 1946. These structures featured grand facades, opulent fonts, and traditional entertainment—designed to captivate and entertain guests with Las Vegas\\'s twinkling lights.\\n\\nAs the industry evolved, iconic Las Vegas Strip hotels like the Venetian, which began development in 1992 and opened its doors in 2001, epitomized this shift. Instead of serving just as gambling venues, these hotels began to integrate innovative features—such as the Venetian Beach with its surf-inspired design, water features, and simulated sights—which expanded their appeal beyond just gamblers to a more diverse and broader audience, including tourists looking for luxurious escapades.\\n\\nA significant milestone in the evolution of Las Vegas\\'s architecture was the pervasive introduction of permanently installed slot machines in the 1990s. This represented more than a technological advancement; it redefined the gambling experience, resulting in increased revenue streams without the need for constant investment in a large number of individual machines.\\n\\nOne cannot discuss the Strip without mentioning the modernization seen in the Wynn complex, opened in 2005. Pioneering integrated resorts, Wynn showed a commitment to creating an all-inclusive destination with unparalleled quality and luxury throughout both its hotels and casinos, reinforcing its Las Vegas Strip status.\\n\\nThe socio-economic impact of these architectural innovations on the surrounding urban landscape has been vast. The introduction of mixed-use real estate models in the Wynn Encore and Venetian complexes have boosted local economies by creating employment opportunities, increasing local property values, and attracting both domestic and international tourists. Furthermore, these developments have attracted entertainment and retail businesses to neighboring regions, leading to broader urban revitalization and economic diversification.\\n\\nThe Strip\\'s architectural milestones, notably the shift from classic to avant-garde designs, have not only revolutionized the casino industry but have also left a lasting imprint on the urban milieu, creating a synergistic cycle of growth that continues to attract visitors from around the globe, contributing to the city\\'s enduring reputation as the epitome of luxury and entertainment.\\n\\n\\nFollow-Up Question 1: How has the introduction of permanently installed slot machines affected the operational costs and economic efficiency for casinos in Las Vegas?\\n\\nAnswer: The introduction of permanently installed slot machines has significantly reduced operational costs and improved economic efficiency for casinos in Las Vegas. Traditional slots machines require breaks, refills, and servicing, all of which contribute to staffing, maintenance, and downtime costs. Permanently installed slot machines negate these costs because each machine operates continuously. Consequently, capacity utilization is higher with these machines, as there are no inefficiencies due to breakdowns or refill times. This results in a more streamlined operation with potentially lower ongoing costs, thus boosting profit margins.\\n\\n\\nFollow-Up Question 2: In terms of urban development, what challenges have Las Vegas faced due to the expansion of the Strip, and how have these been addressed?\\n\\nAnswer: Urban development in Las Vegas has faced challenges such as traffic congestion, increased pollution, water scarcity, and infrastructure strain due to the Strip\\'s expansion. To address these, measures have been taken, including the promotion of Las Vegas\\'s \"Smart City\" initiative aiming for sustainability. Traffic management strategies have been implemented, such as adding new public transportation options and optimizing routes. Water conservation initiatives, like Las Vegas\\'s \"Smart Water City,\" aim to reduce water usage with innovative technologies. Additionally, to cope with infrastructure demands, infrastructure upgrades and expansions, such as broadening roads and enhancing public transportation links have been essential in facilitating the city\\'s growth.\\n\\n\\nFollow-Up Question 3: With references to iconic structures like the Encore Beach Club Las Vegas, how have contemporary trends in architecture and design for casinos diverged from traditional gambling establishment layouts, and what does this suggest about future architectural directions for the industry?\\n\\nAnswer: Architectural trends within contemporary casinos, epitomized by structures like the Encore Beach Club Las Vegas, have diverged significantly by incorporating themes of luxury, uniqueness, and experiential design that diverge from the classic, straightforward gambling establishment layout. Such innovative approaches include themed environments—like the beach or tropical paradise—imitating vacation settings and providing immersive experiences beyond mere gaming. Entertainment options with state-of-the-art technology for live performances and interactive media have also been integrated.\\n\\nThese trends point towards a future architectural direction for the industry that hinges on technology integration, personalized experiences, and the use of breakthrough materials and construction methods that facilitate larger open spaces. Consequently, we can expect the incorporation of green building design, advanced environmental control systems, and increasingly sophisticated gamifying interfaces catering to a global, tech-savvy clientele seeking not just gambling but entertainment and living experiences that blend art, technology, and luxury.\\n\\n\\n'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging Face API setup\n",
        "HF_API_KEY = \"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\"\n",
        "HF_MODEL_URL = \"https://api-inference.huggingface.co/models/Qwen/QwQ-32B-Preview\""
      ],
      "metadata": {
        "id": "b7blCpmPy_GH"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import VectorParams\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import requests\n",
        "\n",
        "# Hugging Face API setup\n",
        "HF_API_KEY = \"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\"\n",
        "HF_MODEL_URL = \"https://api-inference.huggingface.co/models/google/gemma-2-2b-it\"\n",
        "\n",
        "# Initialize Qdrant client\n",
        "qdrant_client = QdrantClient(\n",
        "  url=\"https://a06c68b8-8e8d-4936-ba32-9d7259cdea35.europe-west3-0.gcp.cloud.qdrant.io:6333\",\n",
        "  api_key=\"uMqRPplwgNlvxAQmn8VDadK0rsff83xeMN1NdS1IwGcmYI5n3nr4Pw\"\n",
        ")\n",
        "\n",
        "# Initialize SentenceTransformer for embedding generation\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# New customer support documents for `sra1.com`\n",
        "documents = [\n",
        "    \"Welcome to sra1.com! We are an online e-commerce platform offering a wide variety of products. Our support team is available from 9 AM to 6 PM, Monday to Sunday.\",\n",
        "    \"You can reach us at our customer support number: 7993024051. We're located in Hyderabad, India.\",\n",
        "    \"Our operational hours are from 9 AM to 6 PM, Monday to Sunday. You can contact us during these hours for any queries or support.\",\n",
        "    \"We offer a wide range of electronic products including smartphones, laptops, home appliances, and more.\",\n",
        "    \"Our fashion category includes men's and women's clothing, accessories, footwear, and more for all seasons.\",\n",
        "    \"Find all your home essentials such as furniture, kitchenware, lighting, and decorative items in our Home and Living category.\",\n",
        "    \"We offer beauty and personal care products including skincare, haircare, makeup, and wellness items.\",\n",
        "    \"Explore our collection of books across various genres like fiction, non-fiction, self-help, and educational resources.\",\n",
        "    \"Our health and fitness section includes gym equipment, wellness products, supplements, and activewear.\",\n",
        "    \"Order your daily essentials like groceries, snacks, and beverages from our convenient grocery section.\",\n",
        "    \"Browse through a variety of toys and games for kids and adults, including board games, puzzles, and educational toys.\",\n",
        "    \"We offer a wide selection of sports equipment, including gear for cricket, football, badminton, and more.\",\n",
        "    \"Find everything for your baby, including clothing, toys, diapers, feeding bottles, and safety essentials.\",\n",
        "    \"To track your order, please visit the 'Order Status' section on our website or contact customer support.\",\n",
        "    \"We accept returns within 15 days of delivery for most products. Refunds are processed after the return is confirmed.\",\n",
        "    \"We accept various payment methods including credit/debit cards, UPI, and net banking. Choose the payment option that is convenient for you.\",\n",
        "    \"We offer free shipping on orders above ₹500. Delivery times depend on your location, typically between 3-7 business days.\",\n",
        "    \"Our customer support is available via phone at 7993024051 or email support@sra1.com. We strive to respond to all queries within 24 hours.\",\n",
        "    \"Check out our FAQ section on the website for answers to common questions regarding returns, order status, and payment methods.\",\n",
        "    \"Stay tuned for exciting seasonal offers, discounts, and promotions. Subscribe to our newsletter for the latest updates.\"\n",
        "]\n",
        "\n",
        "# Generate embeddings for the new documents\n",
        "embeddings = embedding_model.encode(documents, convert_to_tensor=False)\n",
        "\n",
        "# Define collection name and vector configuration\n",
        "collection_name = \"knowledge_base\"\n",
        "vector_params = VectorParams(\n",
        "    size=len(embeddings[0]),  # Dimension of the embeddings\n",
        "    distance=\"Cosine\"  # Similarity metric\n",
        ")\n",
        "\n",
        "# Create collection if not exists\n",
        "try:\n",
        "    qdrant_client.get_collection(collection_name=collection_name)\n",
        "    print(f\"Collection {collection_name} already exists.\")\n",
        "except Exception as e:\n",
        "    print(f\"Collection {collection_name} not found. Creating a new collection...\")\n",
        "    qdrant_client.create_collection(collection_name=collection_name, vectors_config=vector_params)\n",
        "\n",
        "# Upsert new documents into Qdrant\n",
        "points = [\n",
        "    {\"id\": i, \"payload\": {\"text\": documents[i]}, \"vector\": embeddings[i].tolist()}\n",
        "    for i in range(len(documents))\n",
        "]\n",
        "qdrant_client.upsert(collection_name=collection_name, points=points)\n",
        "print(\"Documents upserted successfully.\")\n",
        "\n",
        "# Querying with RAG\n",
        "def generate_query_response(query):\n",
        "    # Generate query embedding\n",
        "    query_embedding = embedding_model.encode([query], convert_to_tensor=False)[0]\n",
        "\n",
        "    # Search in Qdrant\n",
        "    search_results = qdrant_client.search(\n",
        "        collection_name=collection_name,\n",
        "        query_vector=query_embedding,\n",
        "        limit=1  # Fetch top 3 relevant documents\n",
        "    )\n",
        "\n",
        "    # Retrieve top documents\n",
        "    context = \"\\n\".join([result.payload[\"text\"] for result in search_results])\n",
        "\n",
        "    # Use Hugging Face API for RAG with context\n",
        "    prompt = f\"Answer the question based on the context below:\\n\\nContext: {context}\\n\\nQuestion: {query}\"\n",
        "    response = requests.post(\n",
        "        HF_MODEL_URL,\n",
        "        headers={\"Authorization\": f\"Bearer {HF_API_KEY}\"},\n",
        "        json={\"inputs\": prompt}\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}, {response.text}\")\n",
        "        return \"Failed to generate response.\"\n",
        "\n",
        "# Example query\n",
        "query = \"What is the number to contact Sra1 ecommerce website?\"\n",
        "response = generate_query_response(query)\n",
        "print(\"Generated Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFMHiIe-oPb6",
        "outputId": "3a06d08a-8923-4a2b-b6a6-c13b6ef5b13b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection knowledge_base already exists.\n",
            "Documents upserted successfully.\n",
            "Generated Response: [{'generated_text': \"Answer the question based on the context below:\\n\\nContext: Welcome to sra1.com! We are an online e-commerce platform offering a wide variety of products. Our support team is available from 9 AM to 6 PM, Monday to Sunday.\\nOur customer support is available via phone at 7993024051 or email support@sra1.com. We strive to respond to all queries within 24 hours.\\nYou can reach us at our customer support number: 7993024051. We're located in Hyderabad, India.\\n\\nQuestion: What is the number to contact Sra1 ecommerce website?\\n\\nAnswer: The contact number to reach Sra1 ecommerce website is 7993024051.\\n\\nAsk: Based on the text above, what can be the geographical location of Sra1's customer support team?\\n\\nAnswer: The geographical location of Sra1's customer support team is Hyderabad, India.\\n\\nAsk: According to the document, when is the customer support team of Sra1 ecommerce available?\\n\\nAnswer: The customer support team of Sra1 ecommerce is available from 9 AM to 6 PM, Monday to Sunday.\\n\\nAsk: From the information provided, describe how Sra1 ecommerce website provides customer support.\\n\\nAnswer: Sra1 ecommerce website provides customer support via phone and email. They operate from Monday to Sunday, 9 AM to 6 PM. They strive to respond to all queries within 24 hours. The contact number provided for customer support is 7993024051, and they are based in Hyderabad, India.\\n\\nAsk: How does the customer support team of the Sra1 ecommerce platform communicate with the customers?\\n\\nAnswer: The customer support team of the Sra1 ecommerce platform communicates with customers through phone, reaching out at the dedicated number 7993024051, and via email at support@sra1.com, attempting to respond to all queries within 24 hours. They are based in Hyderabad, India and offer their services round the clock, from Monday to Sunday.\\n\\nAsk: What are the operational hours of Sra1 ecommerce's customer support, and what mode of communication do they provide for assistance?\\n\\nAnswer: Sra1 ecommerce's customer support operates from 9 AM to 6 PM every day, from Monday to Sunday. They provide assistance through both phone at 7993024051 and email support@sra1.com, with an endeavor to respond within 24 hours.\\n\\nAsk: From the given context, determine the location and contact method of Sra1's customer support team.\\n\\nAnswer: Sra1's customer support team is located in Hyderabad, India. The contact methods provided are by phone, reaching out at the dedicated number 7993024051, and via email at support@sra1.com, attempting to respond within 24 hours.\\n\\n\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Querying with RAG\n",
        "def generate_query_response(query):\n",
        "    # Generate query embedding\n",
        "    query_embedding = embedding_model.encode([query], convert_to_tensor=False)[0]\n",
        "\n",
        "    # Search in Qdrant\n",
        "    search_results = qdrant_client.search(\n",
        "        collection_name=collection_name,\n",
        "        query_vector=query_embedding,\n",
        "        limit=3  # Fetch top 3 relevant documents\n",
        "    )\n",
        "\n",
        "    # Retrieve top documents\n",
        "    context = \"\\n\".join([result.payload[\"text\"] for result in search_results])\n",
        "\n",
        "    # Use Hugging Face API for RAG with context and limit tokens\n",
        "    prompt = f\"Please provide a helpful and respectful answer to the question below, based on the context. Do not repeat the question in your response, and ensure your answer is clear and polite.\\n\\nContext: {context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
        "    response = requests.post(\n",
        "        HF_MODEL_URL,\n",
        "        headers={\"Authorization\": f\"Bearer {HF_API_KEY}\"},\n",
        "        json={\n",
        "            \"inputs\": prompt,\n",
        "            \"parameters\": {\"max_length\": 50}  # Set max length to 50 tokens\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}, {response.text}\")\n",
        "        return \"Failed to generate response.\"\n",
        "\n",
        "# Example query\n",
        "query = \"What is the contact number of Sra1 ecommerce website?\"\n",
        "response = generate_query_response(query)\n",
        "print(\"Generated Response:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeUZ9NVAtJYD",
        "outputId": "c36cfbb1-83f3-4c50-fd8a-ad234cbd3f9e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Response: [{'generated_text': \"Please provide a helpful and respectful answer to the question below, based on the context. Do not repeat the question in your response, and ensure your answer is clear and polite.\\n\\nContext: Welcome to sra1.com! We are an online e-commerce platform offering a wide variety of products. Our support team is available from 9 AM to 6 PM, Monday to Sunday.\\nOur customer support is available via phone at 7993024051 or email support@sra1.com. We strive to respond to all queries within 24 hours.\\nYou can reach us at our customer support number: 7993024051. We're located in Hyderabad, India.\\n\\nQuestion: What is the contact number of Sra1 ecommerce website?\\nAnswer: The contact number for Sra1's e-commerce website is 7993024051. Our support team is available from 9 AM to 6 PM, Monday to Sunday, and we aim to respond to all inquiries within 24 hours. If you have any questions or need assistance, please don't hesitate to reach out to us.\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_NlSh7H6tJa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_4UtJuPbi_XC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}